---
phase: 01.1-web-scraping-revamp
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - lib/scraper/utils.ts
  - lib/scraper/scraper.ts
  - app/api/admin/scraper/run/route.ts
autonomous: true

must_haves:
  truths:
    - "Scraper checks against Business table before saving duplicates"
    - "Duplicate businesses are flagged with match information"
    - "Hours are extracted from Google Places API responses"
    - "Hours stored in ScrapedBusiness metadata"
  artifacts:
    - path: "lib/scraper/utils.ts"
      provides: "Cross-table deduplication function"
      exports: ["checkForDuplicateInDatabase"]
      contains: "db.business.findFirst"
    - path: "lib/scraper/scraper.ts"
      provides: "Hours extraction in transformGooglePlace"
      contains: "opening_hours"
  key_links:
    - from: "lib/scraper/utils.ts"
      to: "prisma Business model"
      via: "findFirst query for deduplication"
      pattern: "db\\.business\\.findFirst"
    - from: "lib/scraper/scraper.ts"
      to: "Google Places API"
      via: "opening_hours field parsing"
      pattern: "place\\.opening_hours"
---

<objective>
Add cross-table deduplication (check both ScrapedBusiness AND Business tables) and extract business hours from Google Places API responses.

Purpose: Currently deduplication only checks within ScrapedBusiness table, allowing duplicates when a business already exists in the main Business table. Hours are also not extracted from Google Places API despite being available. This plan fixes both issues.

Output:
- Enhanced deduplication that checks Business table
- Hours extraction from Google Places API stored in metadata
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01.1-web-scraping-revamp/01.1-RESEARCH.md

# Key files to reference
@lib/scraper/utils.ts
@lib/scraper/scraper.ts
@prisma/schema.prisma
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add cross-table deduplication</name>
  <files>lib/scraper/utils.ts</files>
  <action>
Add a new function `checkForDuplicateInDatabase` to `lib/scraper/utils.ts` that checks BOTH ScrapedBusiness AND Business tables for duplicates.

1. Add db import at top of file (if not present):
```typescript
import { db } from "@/lib/db";
```

2. Add new async function after the existing `checkForDuplicate`:

```typescript
/**
 * Check for duplicate in both ScrapedBusiness and Business tables
 * This prevents creating duplicate entries when a business already exists
 */
export async function checkForDuplicateInDatabase(
  business: Partial<ScrapedBusiness>
): Promise<{
  isDuplicate: boolean;
  existingId?: string;
  matchType?: "scraped" | "business";
  matchField?: "name_address" | "phone" | "name_city";
}> {
  // Build OR conditions for ScrapedBusiness check
  const scrapedConditions: any[] = [];

  if (business.name && business.address) {
    scrapedConditions.push({
      name: { equals: business.name, mode: "insensitive" },
      address: { equals: business.address, mode: "insensitive" },
    });
  }

  if (business.phone) {
    const normalizedPhone = business.phone.replace(/\D/g, "");
    if (normalizedPhone.length >= 10) {
      scrapedConditions.push({ phone: business.phone });
    }
  }

  // Check ScrapedBusiness table first
  if (scrapedConditions.length > 0) {
    const existingScraped = await db.scrapedBusiness.findFirst({
      where: { OR: scrapedConditions },
      select: { id: true, name: true, phone: true },
    });

    if (existingScraped) {
      const matchField = existingScraped.phone === business.phone ? "phone" : "name_address";
      return {
        isDuplicate: true,
        existingId: existingScraped.id,
        matchType: "scraped",
        matchField,
      };
    }
  }

  // Build OR conditions for Business table check
  const businessConditions: any[] = [];

  if (business.name && business.city) {
    businessConditions.push({
      name: { contains: business.name, mode: "insensitive" },
      city: { equals: business.city, mode: "insensitive" },
    });
  }

  if (business.phone) {
    const normalizedPhone = business.phone.replace(/\D/g, "");
    if (normalizedPhone.length >= 10) {
      businessConditions.push({ phone: business.phone });
    }
  }

  // Check Business table
  if (businessConditions.length > 0) {
    const existingBusiness = await db.business.findFirst({
      where: { OR: businessConditions },
      select: { id: true, name: true, phone: true },
    });

    if (existingBusiness) {
      const matchField = existingBusiness.phone === business.phone ? "phone" : "name_city";
      return {
        isDuplicate: true,
        existingId: existingBusiness.id,
        matchType: "business",
        matchField,
      };
    }
  }

  return { isDuplicate: false };
}
```

3. Export the new function at the end of the file if using named exports.

Note: This function is async because it queries the database. The existing `checkForDuplicate` function remains for in-memory deduplication during a scrape batch. The new function is for pre-save database checks.
  </action>
  <verify>
Run TypeScript check: `npx tsc --noEmit lib/scraper/utils.ts`
Verify function exists: `grep -n "checkForDuplicateInDatabase" lib/scraper/utils.ts`
Verify Business table query: `grep -n "db.business.findFirst" lib/scraper/utils.ts`
  </verify>
  <done>
- checkForDuplicateInDatabase function exists in utils.ts
- Function checks ScrapedBusiness table for exact name+address or phone
- Function checks Business table for name+city or phone
- Function returns matchType indicating which table matched
- Function is async and properly queries database
  </done>
</task>

<task type="auto">
  <name>Task 2: Extract hours from Google Places API</name>
  <files>lib/scraper/scraper.ts</files>
  <action>
Enhance `transformGooglePlace` in `lib/scraper/scraper.ts` to extract business hours from the Google Places API response.

1. Find the `transformGooglePlace` function (around line 370).

2. Add hours extraction before the return statement:

```typescript
async function transformGooglePlace(
  place: any,
  config: ScraperConfig
): Promise<ScrapedBusiness | null> {
  const combinedText = `${place.name} ${place.formatted_address || ""} ${
    place.types?.join(" ") || ""
  }`;

  const { score, signals } = analyzeMuslimSignals(combinedText, place.name);
  const { category, alternatives } = categorizeBusiness(combinedText, place.name);
  const { detected, suggested } = detectTags(combinedText, place.name, signals);

  // Extract hours from opening_hours
  let hours: Record<string, string> | undefined;
  if (place.opening_hours?.weekday_text) {
    hours = {};
    const dayMap: Record<string, string> = {
      "Monday": "monday",
      "Tuesday": "tuesday",
      "Wednesday": "wednesday",
      "Thursday": "thursday",
      "Friday": "friday",
      "Saturday": "saturday",
      "Sunday": "sunday",
    };

    for (const dayText of place.opening_hours.weekday_text) {
      // Format: "Monday: 9:00 AM â€“ 9:00 PM" or "Monday: Closed"
      const colonIndex = dayText.indexOf(":");
      if (colonIndex > 0) {
        const day = dayText.substring(0, colonIndex).trim();
        const time = dayText.substring(colonIndex + 1).trim();
        const dayKey = dayMap[day];
        if (dayKey) {
          hours[dayKey] = time;
        }
      }
    }
  }

  // Extract price level (1-4 scale from Google)
  let priceRange: "BUDGET" | "MODERATE" | "PREMIUM" | "LUXURY" | undefined;
  if (place.price_level !== undefined) {
    const priceMap: Record<number, "BUDGET" | "MODERATE" | "PREMIUM" | "LUXURY"> = {
      0: "BUDGET",
      1: "BUDGET",
      2: "MODERATE",
      3: "PREMIUM",
      4: "LUXURY",
    };
    priceRange = priceMap[place.price_level];
  }

  return {
    name: place.name,
    description: place.editorial_summary?.overview,
    category,
    suggestedCategories: alternatives,
    tags: detected,
    suggestedTags: suggested,
    address: place.formatted_address?.split(",")[0] || "",
    city: config.city,
    state: config.state,
    zipCode: config.zipCode || "",
    latitude: place.geometry?.location?.lat,
    longitude: place.geometry?.location?.lng,
    phone: place.formatted_phone_number,
    website: place.website,
    // NEW: Include hours in the result
    hours,
    priceRange,
    averageRating: place.rating,
    totalReviews: place.user_ratings_total,
    confidence: score,
    signals,
    verificationLevel: determineVerificationLevel("google_places", signals, score),
    source: "google_places",
    sourceUrl: `https://www.google.com/maps/place/?q=place_id:${place.place_id}`,
    sourceId: place.place_id,
    photos: place.photos?.map((p: any) => ({
      url: `https://maps.googleapis.com/maps/api/place/photo?maxwidth=800&photoreference=${p.photo_reference}&key=${process.env.GOOGLE_PLACES_API_KEY}`,
      source: "google",
    })),
    scrapedAt: new Date(),
  };
}
```

3. Update the ScrapedBusiness type in `lib/scraper/types.ts` if it doesn't already have `hours` and `priceRange` fields. Check first with grep.

4. Also update the mock data generator `generateMockBusinesses` to include sample hours:

```typescript
// In generateMockBusinesses, add to the business object:
hours: {
  monday: "9:00 AM - 9:00 PM",
  tuesday: "9:00 AM - 9:00 PM",
  wednesday: "9:00 AM - 9:00 PM",
  thursday: "9:00 AM - 9:00 PM",
  friday: "9:00 AM - 10:00 PM",
  saturday: "10:00 AM - 10:00 PM",
  sunday: "10:00 AM - 8:00 PM",
},
```
  </action>
  <verify>
Run TypeScript check: `npx tsc --noEmit lib/scraper/scraper.ts`
Verify hours extraction: `grep -n "opening_hours" lib/scraper/scraper.ts`
Verify price level extraction: `grep -n "price_level" lib/scraper/scraper.ts`
  </verify>
  <done>
- transformGooglePlace extracts opening_hours.weekday_text
- Hours converted to Record<string, string> format
- Price level converted to PriceRange enum
- Mock data includes sample hours
- ScrapedBusiness type supports hours field
  </done>
</task>

</tasks>

<verification>
1. TypeScript compiles without errors:
   ```bash
   npx tsc --noEmit
   ```

2. Cross-table dedup function exists:
   ```bash
   grep -A3 "export async function checkForDuplicateInDatabase" lib/scraper/utils.ts
   ```

3. Hours extraction exists:
   ```bash
   grep -B2 -A5 "opening_hours" lib/scraper/scraper.ts
   ```

4. Business table query in dedup:
   ```bash
   grep "db.business.findFirst" lib/scraper/utils.ts
   ```
</verification>

<success_criteria>
- [ ] checkForDuplicateInDatabase function exists in lib/scraper/utils.ts
- [ ] Function queries both ScrapedBusiness AND Business tables
- [ ] Function returns matchType to identify which table matched
- [ ] transformGooglePlace extracts hours from opening_hours.weekday_text
- [ ] Hours stored in scraped business result
- [ ] TypeScript compiles without errors
</success_criteria>

<output>
After completion, create `.planning/phases/01.1-web-scraping-revamp/01.1-02-SUMMARY.md`
</output>
